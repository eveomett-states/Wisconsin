{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import maup\n",
    "import time\n",
    "from maup import smart_repair\n",
    "from gerrychain import Graph\n",
    "\n",
    "maup.progress.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = Wisconsin\n",
    "state_ab = \"wi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "1. Download all the data in directory \"tn_data\"\n",
    "2. Extract them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = state_ab + \"_data/\"\n",
    "population1_data = \"./{}{}_pl2020_b/{}_pl2020_p1_b.shp\".format(data_folder, state_ab, state_ab)\n",
    "population2_data = \"./{}{}_pl2020_b/{}_pl2020_p2_b.shp\".format(data_folder, state_ab, state_ab)\n",
    "vap_data =  \"./{}{}_pl2020_b/{}_pl2020_p4_b.shp\".format(data_folder, state_ab, state_ab)\n",
    "vest20_data = \"./{}{}_vest_20/{}_vest_20.shp\".format(data_folder, state_ab, state_ab)\n",
    "vest18_data = \"./{}{}_vest_18/{}_vest_18.shp\".format(data_folder, state_ab, state_ab)\n",
    "vest16_data = \"./{}{}_vest_16/{}_vest_16.shp\".format(data_folder, state_ab, state_ab)\n",
    "cd_data = \"./{}{}_cong_adopted_2022/POLYGON.shp\".format(data_folder, state_ab)\n",
    "send_data = \"./{}{}_sldu_adopted_2022/Senate_Districts_2021_Johnson_v_WEC.shp\".format(data_folder, state_ab)\n",
    "hdist_data = \"./{}{}_sldl_adopted_2022/Assembly_Districts_2021_Johnson_v_WEC.shp\".format(data_folder, state_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_smart_repair(df):\n",
    "    # change it to the UTM it needs for smart_repair\n",
    "    df = df.to_crs(df.estimate_utm_crs())\n",
    "    df = smart_repair(df)\n",
    "    if maup.doctor(df):\n",
    "        print('smart_repair successful')\n",
    "            \n",
    "        # change it back to this UTM for this data\n",
    "        df = df.to_crs('EPSG:4269')\n",
    "    else:\n",
    "        raise Exception('smart_repair failed')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_district(dist_df, dist_name, election_df, col_name):\n",
    "    # check if it needs to be smart_repair\n",
    "    if maup.doctor(dist_df) != True:\n",
    "        dist_df = do_smart_repair(dist_df)\n",
    "    \n",
    "    election_df = gpd.GeoDataFrame(election_df, crs=\"EPSG:4269\")\n",
    "    \n",
    "    # assign the pricincts\n",
    "    precincts_to_district_assignment = maup.assign(election_df.geometry, dist_df.geometry)\n",
    "    election_df[dist_name] = precincts_to_district_assignment\n",
    "    for precinct_index in range(len(election_df)):\n",
    "        election_df.at[precinct_index, dist_name] = dist_df.at[election_df.at[precinct_index, dist_name], col_name]\n",
    "    \n",
    "    return election_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(original, year):\n",
    "    party = original[6]\n",
    "    if party == 'R' or party == 'D':\n",
    "        return original[3:6] + year + original[6]\n",
    "    else:\n",
    "        return original[3:6] + year + 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_col = ['TOTPOP', 'HISP', 'NH_WHITE', 'NH_BLACK', 'NH_AMIN', 'NH_ASIAN', 'NH_NHPI', 'NH_OTHER', 'NH_2MORE', 'H_WHITE', 'H_BLACK', 'H_AMIN', 'H_ASIAN', 'H_NHPI', 'H_OTHER', 'H_2MORE', 'VAP', 'HVAP', 'WVAP', 'BVAP', 'AMINVAP', 'ASIANVAP', 'NHPIVAP', 'OTHERVAP', '2MOREVAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_population(population, df):\n",
    "    pop_check = pd.DataFrame({\n",
    "        'pop_col': pop_col,\n",
    "        'population_df': population[pop_col].sum(), \n",
    "        'vest_base': df[pop_col].sum(),\n",
    "        'equal': [x == y for x, y in zip(population[pop_col].sum(), df[pop_col].sum())]\n",
    "    })\n",
    "    if pop_check['equal'].mean() < 1:\n",
    "        print(pop_check)\n",
    "        raise Exception(\"population doesn't agree\")\n",
    "\n",
    "    else:\n",
    "        print(\"population agrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vest(vest, df, year, population, start_col):    \n",
    "     # check if it needs to be smart_repair\n",
    "    if maup.doctor(vest) != True:\n",
    "        vest = do_smart_repair(vest)\n",
    "    \n",
    "    # rename the columns\n",
    "    original_col = vest.columns[start_col:-1]\n",
    "    new_col = [rename(i, year) for i in original_col]\n",
    "    rename_dict = dict(zip(original_col, new_col))\n",
    "    vest = vest.rename(columns=rename_dict)\n",
    "    vest = vest.groupby(level=0, axis=1).sum() # combine all the other party's vote into columns with sufix \"O\"\n",
    "    col_name = list(set(new_col))\n",
    "    col_name.sort()\n",
    "    \n",
    "    # make the blocks from precincts by weight\n",
    "    vest = gpd.GeoDataFrame(vest, crs=\"EPSG:4269\")\n",
    "    election_in_block = population[[\"VAP\", 'geometry']] # population_df is in block scale\n",
    "    blocks_to_precincts_assignment = maup.assign(election_in_block.geometry, vest.geometry)\n",
    "\n",
    "    weights = election_in_block[\"VAP\"] / blocks_to_precincts_assignment.map(election_in_block[\"VAP\"].groupby(blocks_to_precincts_assignment).sum())\n",
    "    weights = weights.fillna(0)\n",
    "    prorated = maup.prorate(blocks_to_precincts_assignment, vest[col_name], weights)\n",
    "    election_in_block[col_name] = prorated\n",
    "\n",
    "    # assign blocks to precincts\n",
    "    election_in_block = gpd.GeoDataFrame(election_in_block, crs=\"EPSG:4269\")\n",
    "    df = gpd.GeoDataFrame(df, crs=\"EPSG:4269\")\n",
    "    block_to_pricinct_assginment = maup.assign(election_in_block.geometry, df.geometry)\n",
    "    df[col_name] = election_in_block[col_name].groupby(block_to_pricinct_assginment).sum()\n",
    "    df = df.groupby(level=0, axis=1).sum()\n",
    "    \n",
    "    # check if population agrees\n",
    "    check_population(population, df)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "population1_df = gpd.read_file(population1_data)\n",
    "population2_df = gpd.read_file(population2_data)\n",
    "vap_df = gpd.read_file(vap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "population2_df = population2_df.drop(columns=['SUMLEV', 'LOGRECNO', 'GEOID', 'COUNTY', 'geometry'])\n",
    "vap_df = vap_df.drop(columns=['SUMLEV', 'LOGRECNO', 'GEOID', 'COUNTY', 'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.merge(population1_df, population2_df, on='GEOID20')\n",
    "population_df = pd.merge(population_df, vap_df, on='GEOID20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203059/203059 [03:22<00:00, 1003.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maup.doctor(population_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df['H_WHITE'] = population_df.apply(lambda t: t['P0010003'] - t['P0020005'], 1)\n",
    "population_df['H_BLACK'] = population_df.apply(lambda t: t['P0010004'] - t['P0020006'], 1)\n",
    "population_df['H_AMIN'] = population_df.apply(lambda t: t['P0010005'] - t['P0020007'], 1)\n",
    "population_df['H_ASIAN'] = population_df.apply(lambda t: t['P0010006'] - t['P0020008'], 1)\n",
    "population_df['H_NHPI'] = population_df.apply(lambda t: t['P0010007'] - t['P0020009'], 1)\n",
    "population_df['H_OTHER'] = population_df.apply(lambda t: t['P0010008'] - t['P0020010'], 1)\n",
    "population_df['H_2MORE'] = population_df.apply(lambda t: t['P0010009'] - t['P0020011'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {'P0020001': 'TOTPOP', 'P0020002': 'HISP', 'P0020005': 'NH_WHITE', 'P0020006': 'NH_BLACK', 'P0020007': 'NH_AMIN',\n",
    "                    'P0020008': 'NH_ASIAN', 'P0020009': 'NH_NHPI', 'P0020010': 'NH_OTHER', 'P0020011': 'NH_2MORE',\n",
    "                    'P0040001': 'VAP', 'P0040002': 'HVAP', 'P0040005': 'WVAP', 'P0040006': 'BVAP', 'P0040007': 'AMINVAP',\n",
    "                                        'P0040008': 'ASIANVAP', 'P0040009': 'NHPIVAP', 'P0040010': 'OTHERVAP', 'P0040011': '2MOREVAP'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df.rename(columns=rename_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 175.37it/s]\n"
     ]
    }
   ],
   "source": [
    "cong_df = gpd.read_file(cd_data)\n",
    "if maup.doctor(cong_df) != True:\n",
    "    cong_df = do_smart_repair(cong_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the vest 20 data\n",
    "\n",
    "Now using it as a \"base pricinct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vest_base(vest, start_col, year):\n",
    "    original_col = vest.columns[start_col:-1]\n",
    "    new_col = [rename(i, year) for i in original_col]\n",
    "    rename_dict = dict(zip(original_col, new_col))\n",
    "    vest = vest.rename(columns=rename_dict)\n",
    "    vest = vest.groupby(level=0, axis=1).sum()\n",
    "    vest = gpd.GeoDataFrame(vest, crs=\"EPSG:4269\")\n",
    "    \n",
    "    return vest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if vest20 can be used as base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7090/7090 [00:11<00:00, 604.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14 overlaps.\n",
      "There are 30 holes.\n",
      "There are some invalid geometries.\n",
      "Snapping all geometries to a grid with precision 10^( -5 ) to avoid GEOS errors.\n",
      "Identifying overlaps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9927/9927 [00:10<00:00, 949.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving overlaps...\n",
      "Assigning order 2 pieces...\n",
      "1 gaps will remain unfilled, because they either are not simply connected or exceed the area threshold.\n",
      "Filling gaps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps to simplify: 100%|██████████| 30/30 [00:57<00:00,  1.92s/it]\n",
      "Gaps to fill: 100%|██████████| 15/15 [00:36<00:00,  2.43s/it]\n",
      "100%|██████████| 7090/7090 [00:11<00:00, 635.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 holes.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "smart_repair failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aagarwal/Desktop/Redestring AI/Wisconsin/wi.ipynb Cell 24\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vest20 \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(vest20_data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m maup\u001b[39m.\u001b[39mdoctor(vest20) \u001b[39m!=\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     vest20 \u001b[39m=\u001b[39m do_smart_repair(vest20)\n",
      "\u001b[1;32m/Users/aagarwal/Desktop/Redestring AI/Wisconsin/wi.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mto_crs(\u001b[39m'\u001b[39m\u001b[39mEPSG:4269\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X32sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39msmart_repair failed\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X32sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "\u001b[0;31mException\u001b[0m: smart_repair failed"
     ]
    }
   ],
   "source": [
    "vest20 = gpd.read_file(vest20_data)\n",
    "if maup.doctor(vest20) != True:\n",
    "    vest20 = do_smart_repair(vest20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "GEOSException",
     "evalue": "TopologyException: side location conflict at -90.602971698191013 44.9442325988297. This can occur if the input geometry is invalid.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGEOSException\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/aagarwal/Desktop/Redestring AI/Wisconsin/wi.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#Y110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vest18 \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(vest18_data)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#Y110sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m maup\u001b[39m.\u001b[39mdoctor(vest18) \u001b[39m!=\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#Y110sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     vest18 \u001b[39m=\u001b[39m do_smart_repair(vest18)\n",
      "File \u001b[0;32m~/anaconda3/envs/gerry/lib/python3.11/site-packages/maup/repair.py:284\u001b[0m, in \u001b[0;36mdoctor\u001b[0;34m(source, target, silent, accept_holes)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[39mDetects quality issues in a given set of source and target geometries. Quality\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[39missues include overlaps, gaps, invalid geometries, non-perfect\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39mFalse. (Default is accept_holes = False.)\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    283\u001b[0m shapefiles \u001b[39m=\u001b[39m [source]\n\u001b[0;32m--> 284\u001b[0m source_union \u001b[39m=\u001b[39m unary_union(get_geometries(source))\n\u001b[1;32m    286\u001b[0m health_check \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/gerry/lib/python3.11/site-packages/shapely/ops.py:135\u001b[0m, in \u001b[0;36mCollectionOperator.unary_union\u001b[0;34m(self, geoms)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munary_union\u001b[39m(\u001b[39mself\u001b[39m, geoms):\n\u001b[1;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the union of a sequence of geometries\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[1;32m    132\u001b[0m \u001b[39m    Usually used to convert a collection into the smallest set of polygons\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m    that cover the same area.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m shapely\u001b[39m.\u001b[39munion_all(geoms, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/gerry/lib/python3.11/site-packages/shapely/decorators.py:77\u001b[0m, in \u001b[0;36mmultithreading_enabled.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m array_args:\n\u001b[1;32m     76\u001b[0m         arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[39mfor\u001b[39;00m arr, old_flag \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(array_args, old_flags):\n",
      "File \u001b[0;32m~/anaconda3/envs/gerry/lib/python3.11/site-packages/shapely/set_operations.py:419\u001b[0m, in \u001b[0;36munion_all\u001b[0;34m(geometries, grid_size, axis, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgrid_size parameter only accepts scalar values\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39munary_union_prec(collections, grid_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 419\u001b[0m \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39munary_union(collections, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mGEOSException\u001b[0m: TopologyException: side location conflict at -90.602971698191013 44.9442325988297. This can occur if the input geometry is invalid."
     ]
    }
   ],
   "source": [
    "vest18 = gpd.read_file(vest18_data)\n",
    "if maup.doctor(vest18) != True:\n",
    "    vest18 = do_smart_repair(vest18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6872/6872 [00:17<00:00, 398.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2548 overlaps.\n",
      "There are 54201 holes.\n",
      "There are some invalid geometries.\n",
      "Snapping all geometries to a grid with precision 10^( -5 ) to avoid GEOS errors.\n",
      "Identifying overlaps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118959/118959 [10:09<00:00, 195.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving overlaps...\n",
      "Assigning order 2 pieces...\n",
      "Assigning order 3 pieces...\n",
      "3 gaps will remain unfilled, because they either are not simply connected or exceed the area threshold.\n",
      "Filling gaps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps to simplify: 54214it [27:31:24,  1.83s/it]                               \n",
      "Gaps to fill: 100%|██████████| 1784/1784 [1:24:13<00:00,  2.83s/it]\n",
      "100%|██████████| 6872/6872 [00:11<00:00, 602.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 holes.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "smart_repair failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aagarwal/Desktop/Redestring AI/Wisconsin/wi.ipynb Cell 26\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vest16 \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(vest16_data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m maup\u001b[39m.\u001b[39mdoctor(vest16) \u001b[39m!=\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     vest16 \u001b[39m=\u001b[39m do_smart_repair(vest16)\n",
      "\u001b[1;32m/Users/aagarwal/Desktop/Redestring AI/Wisconsin/wi.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mto_crs(\u001b[39m'\u001b[39m\u001b[39mEPSG:4269\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39msmart_repair failed\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Wisconsin/wi.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "\u001b[0;31mException\u001b[0m: smart_repair failed"
     ]
    }
   ],
   "source": [
    "vest16 = gpd.read_file(vest16_data)\n",
    "if maup.doctor(vest16) != True:\n",
    "    vest16 = do_smart_repair(vest16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_col = 6\n",
    "vest_base_data = vest20\n",
    "year = '20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_base = add_vest_base(vest_base_data, start_col, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vap and population have the same GEOID20\n",
    "blocks_to_precincts_assignment = maup.assign(population_df.geometry, vest_base.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_base[pop_col] = population_df[pop_col].groupby(blocks_to_precincts_assignment).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = gpd.GeoDataFrame(vest_base, crs=\"EPSG:4269\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if population agrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'pop_col': pop_col,\n",
    "    'population_df': population_df[pop_col].sum(), \n",
    "    'vest_base': vest_base[pop_col].sum(),\n",
    "    'equal': [x == y for x, y in zip(population_df[pop_col].sum(), vest_base[pop_col].sum())]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more vest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest18 = gpd.read_file(vest18_data)\n",
    "vest16 = gpd.read_file(vest16_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest18.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest16.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the result here\n",
    "election_df = add_vest(vest18, election_df, '18', population_df, start_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = add_vest(vest16, election_df, '16', population_df, start_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Add the district data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send = gpd.read_file(send_data)\n",
    "hdist = gpd.read_file(hdist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = add_district(cong_df, \"CD\", election_df, \"CONG_DIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send.to_crs('EPSG:4269', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = add_district(send, \"SEND\", election_df, \"DISTRICT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdist = hdist.to_crs(\"EPSG:4269\")\n",
    "election_df = add_district(hdist, \"HDIST\", election_df, \"DISTRICT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the base precinct year after the precinct information column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_columns = {}\n",
    "if 'COUNTYFP' + year not in election_df.columns:\n",
    "    base_columns = {\n",
    "        'STATEFP':'STATEFP'+year,\n",
    "        'COUNTYFP':'COUNTYFP'+year,\n",
    "        'VTDST':'VTDST'+year,\n",
    "        'PRECINCT':'PRECINCT'+year,\n",
    "        'GEOID':'GEOID'+year,\n",
    "        'NAME':'NAME'+year}\n",
    "election_df.rename(columns=base_columns, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the columns\n",
    "fixed_columns = [\n",
    "    'STATEFP'+year,\n",
    "    'COUNTYFP'+year,\n",
    "    'VTDST'+year,\n",
    "    'PRECINCT'+year,\n",
    "    'GEOID'+year,\n",
    "    'NAME'+year,\n",
    "    'CD',\n",
    "    'SEND',\n",
    "    'HDIST',\n",
    "    'TOTPOP',\n",
    "    'NH_2MORE',\n",
    "    'NH_AMIN',\n",
    "    'NH_ASIAN',\n",
    "    'NH_BLACK',\n",
    "    'NH_NHPI',\n",
    "    'NH_OTHER',\n",
    "    'NH_WHITE',\n",
    "    'HISP',\n",
    "    'H_AMIN',\n",
    "    'H_ASIAN',\n",
    "    'H_BLACK',\n",
    "    'H_NHPI',\n",
    "    'H_OTHER',\n",
    "    'H_WHITE',\n",
    "    'H_2MORE',\n",
    "    'VAP',\n",
    "    'HVAP',\n",
    "    'WVAP',\n",
    "    'BVAP',\n",
    "    'AMINVAP',\n",
    "    'ASIANVAP',\n",
    "    'NHPIVAP',\n",
    "    'OTHERVAP',\n",
    "    '2MOREVAP']\n",
    "\n",
    "election_columns = [col for col in election_df.columns if col not in fixed_columns]\n",
    "final_col = fixed_columns + election_columns\n",
    "election_df = election_df[final_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# store the result in directory \"il\"\n",
    "directory = \"./{}\".format(state_ab)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "shapefile_path = \"./{}/{}.shp\".format(state_ab, state_ab)\n",
    "geojson_path = './{}/{}.geojson'.format(state_ab, state_ab)\n",
    "json_path = \"./{}/{}.json\".format(state_ab, state_ab)\n",
    "\n",
    "# Check if the shapefile or geojson file already exists\n",
    "if os.path.exists(shapefile_path):\n",
    "    os.remove(shapefile_path)\n",
    "if os.path.exists(geojson_path):\n",
    "    os.remove(geojson_path)\n",
    "\n",
    "election_df.to_file(shapefile_path)\n",
    "election_df.to_file(geojson_path, driver='GeoJSON')\n",
    "\n",
    "# Only do once to build json and read from file when generating ensembles\n",
    "graph = Graph.from_file(shapefile_path, ignore_errors=True)\n",
    "graph.to_json(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile_path = \"./{}/{}.shp\".format(state_ab, state_ab)\n",
    "shape=gpd.read_file(shapefile_path)\n",
    "shape.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gerry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
